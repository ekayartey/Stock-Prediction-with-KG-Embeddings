{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Updating the existing NER model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import re\n",
    "import spacy\n",
    "from spacy.lang.en import English\n",
    "from spacy import displacy\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load spaCy model\n",
    "nlp = spacy.load(\"en_core_web_lg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 681,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting the pipeline component\n",
    "ner=nlp.get_pipe(\"ner\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 702,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training data\n",
    "TRAIN_DATA = [\n",
    "            (\"Activist Shareholders have launched more Campaigns.\",{\"entities\":[(0,21,\"ORG\")]}),\n",
    "            (\"Appeals Court ruled for Microsoft.\",{\"entities\":[(0,13,\"ORG\")]}),\n",
    "            (\"ARM Processor threatens Intel dominance.\",{\"entities\":[(0,13,\"PRODUCT\")]}),\n",
    "            (\"Business Survey has warned of China protectionism.\",{\"entities\":[(0,15,\"PRODUCT\")]}),\n",
    "            (\"Code update has crashed Bing search engine.\",{\"entities\":[(0,4,\"PRODUCT\")]}),\n",
    "            (\"Consumer Reports has pulled its recommended rating.\",{\"entities\":[(0,16,\"ORG\")]}),\n",
    "            (\"Dow has hit Low.\",{\"entities\":[(0,3,\"ORG\")]}),\n",
    "            (\"Equity Markets rise by Technology stock gains.\",{\"entities\":[(0,14,\"ORG\")]}),\n",
    "            (\"Forex Traders questions Apple tax row.\",{\"entities\":[(0,13,\"ORG\")]}),\n",
    "            (\"Futures rise by investors earnings.\",{\"entities\":[(0,7,\"PRODUCT\")]}),\n",
    "            (\"Lizard Squad has hacked Lenovo website.\",{\"entities\":[(0,12,\"ORG\")]}),\n",
    "            (\"Social Media Firms have reduced online hate speech.\",{\"entities\":[(7,18,\"ORG\")]}),\n",
    "            (\"Nasdaq falls by Technology stock loss.\",{\"entities\":[(0,6,\"PRODUCT\")]}),\n",
    "            (\"Nikkei Index fell on profit taking.\",{\"entities\":[(0,6,\"PRODUCT\")]}),\n",
    "            (\"Oil prices rises on OPEC deal.\",{\"entities\":[(0,3,\"PRODUCT\")]}),\n",
    "            (\"Pounds sterling falls after UK election shock.\",{\"entities\":[(0,6,\"MONEY\")]}),\n",
    "            (\"Security Experts find ransomware worm clues.\",{\"entities\":[(0,16,\"ORG\")]}),\n",
    "            (\"Business Software Alliance has urged the U.S. Trade Representative.\",{\"entities\":[(9,26,\"ORG\")]}),\n",
    "            (\"Tax Bill eats BarnesNoble profit.\",{\"entities\":[(0,8,\"PRODUCT\")]}),\n",
    "            (\"Tax Reforms threatens Bond Market.\",{\"entities\":[(0,11,\"PRODUCT\")]}),\n",
    "            (\"Tay bot crashed on racist tweets.\",{\"entities\":[(0,3,\"PRODUCT\")]}),\n",
    "            (\"Tech Firms would tackle extremism.\",{\"entities\":[(0,10,\"ORG\")]}),\n",
    "            (\"Wall Street rises by Technology stock gains.\",{\"entities\":[(0,11,\"ORG\")]}),\n",
    "            (\"Windows upgrade has met criticism.\",{\"entities\":[(0,7,\"PRODUCT\")]})\n",
    "             ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 703,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding labels to the `ner`\n",
    "\n",
    "for _, annotations in TRAIN_DATA:\n",
    "    for ent in annotations.get(\"entities\"):\n",
    "        ner.add_label(ent[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 704,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Disable pipeline components you dont need to change\n",
    "pipe_exceptions = [\"ner\", \"trf_wordpiecer\", \"trf_tok2vec\"]\n",
    "unaffected_pipes = [pipe for pipe in nlp.pipe_names if pipe not in pipe_exceptions]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 706,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import requirements\n",
    "import random\n",
    "from spacy.util import minibatch, compounding\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 707,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Losses {'ner': 14.266927182674408}\n",
      "Losses {'ner': 23.875394094502553}\n",
      "Losses {'ner': 33.928607855777955}\n",
      "Losses {'ner': 47.70458920953752}\n",
      "Losses {'ner': 55.095878325486865}\n",
      "Losses {'ner': 65.77533700325557}\n",
      "Losses {'ner': 5.159110188404156}\n",
      "Losses {'ner': 14.296669818380906}\n",
      "Losses {'ner': 21.32342330218671}\n",
      "Losses {'ner': 27.941490478457126}\n",
      "Losses {'ner': 39.898399042540404}\n",
      "Losses {'ner': 44.528372298744216}\n",
      "Losses {'ner': 3.697652095463127}\n",
      "Losses {'ner': 9.611559730255976}\n",
      "Losses {'ner': 13.920592521550134}\n",
      "Losses {'ner': 19.108732437802246}\n",
      "Losses {'ner': 27.399660565977683}\n",
      "Losses {'ner': 39.15907766026794}\n",
      "Losses {'ner': 9.930829423014075}\n",
      "Losses {'ner': 15.00798585240409}\n",
      "Losses {'ner': 21.80606380824611}\n",
      "Losses {'ner': 23.381429198337173}\n",
      "Losses {'ner': 33.44686221531538}\n",
      "Losses {'ner': 35.211631144768944}\n",
      "Losses {'ner': 10.010283339768648}\n",
      "Losses {'ner': 20.69887478009332}\n",
      "Losses {'ner': 29.16814612624512}\n",
      "Losses {'ner': 35.22658518170283}\n",
      "Losses {'ner': 39.963183988857054}\n",
      "Losses {'ner': 49.087835578608065}\n",
      "Losses {'ner': 8.28629557788372}\n",
      "Losses {'ner': 13.130258491873974}\n",
      "Losses {'ner': 22.334305135678733}\n",
      "Losses {'ner': 29.102770516328746}\n",
      "Losses {'ner': 36.364364497618226}\n",
      "Losses {'ner': 39.73278702262178}\n",
      "Losses {'ner': 8.021768152768345}\n",
      "Losses {'ner': 13.799338266308041}\n",
      "Losses {'ner': 19.84543259596103}\n",
      "Losses {'ner': 34.04518254255527}\n",
      "Losses {'ner': 43.85427901733783}\n",
      "Losses {'ner': 52.23579345822509}\n",
      "Losses {'ner': 1.9690238032926572}\n",
      "Losses {'ner': 8.632039289310342}\n",
      "Losses {'ner': 15.851326885953313}\n",
      "Losses {'ner': 18.170136485568946}\n",
      "Losses {'ner': 20.246269404035274}\n",
      "Losses {'ner': 26.86436553865269}\n",
      "Losses {'ner': 5.373696482569528}\n",
      "Losses {'ner': 8.803462700223633}\n",
      "Losses {'ner': 12.861792038307783}\n",
      "Losses {'ner': 16.53658921747609}\n",
      "Losses {'ner': 21.54811508711117}\n",
      "Losses {'ner': 26.884684353446744}\n",
      "Losses {'ner': 7.993882101065537}\n",
      "Losses {'ner': 13.404799437152178}\n",
      "Losses {'ner': 16.516716687641747}\n",
      "Losses {'ner': 20.691249356073968}\n",
      "Losses {'ner': 27.79127445833319}\n",
      "Losses {'ner': 32.58811089226538}\n",
      "Losses {'ner': 7.799153638606981}\n",
      "Losses {'ner': 8.706120217223884}\n",
      "Losses {'ner': 12.651272099824723}\n",
      "Losses {'ner': 16.39831890574294}\n",
      "Losses {'ner': 21.90548948583762}\n",
      "Losses {'ner': 24.9018350744185}\n",
      "Losses {'ner': 2.12720278509903}\n",
      "Losses {'ner': 8.359530028797849}\n",
      "Losses {'ner': 15.516466685481532}\n",
      "Losses {'ner': 18.914320408284965}\n",
      "Losses {'ner': 22.935901722961518}\n",
      "Losses {'ner': 25.102319399135723}\n",
      "Losses {'ner': 5.576105495236789}\n",
      "Losses {'ner': 6.634424149583992}\n",
      "Losses {'ner': 21.496853326701512}\n",
      "Losses {'ner': 26.33990468098591}\n",
      "Losses {'ner': 28.592225957284114}\n",
      "Losses {'ner': 31.748607428665338}\n",
      "Losses {'ner': 5.2276069876338624}\n",
      "Losses {'ner': 9.697420968552706}\n",
      "Losses {'ner': 16.560621702031085}\n",
      "Losses {'ner': 17.00035397300394}\n",
      "Losses {'ner': 22.14442800401247}\n",
      "Losses {'ner': 26.24397222525312}\n",
      "Losses {'ner': 5.592550265138925}\n",
      "Losses {'ner': 12.101356942101148}\n",
      "Losses {'ner': 16.486779014998348}\n",
      "Losses {'ner': 16.65942328162594}\n",
      "Losses {'ner': 21.18028893818949}\n",
      "Losses {'ner': 28.64263268385797}\n",
      "Losses {'ner': 4.37203942119686}\n",
      "Losses {'ner': 9.520593600574102}\n",
      "Losses {'ner': 11.698131209870098}\n",
      "Losses {'ner': 16.95869856787191}\n",
      "Losses {'ner': 20.250256576534714}\n",
      "Losses {'ner': 20.636499637977142}\n",
      "Losses {'ner': 0.28064559191957983}\n",
      "Losses {'ner': 2.1656240041862986}\n",
      "Losses {'ner': 6.885192582099677}\n",
      "Losses {'ner': 11.162053983039385}\n",
      "Losses {'ner': 13.676022523200974}\n",
      "Losses {'ner': 16.653677533632465}\n",
      "Losses {'ner': 1.7030838214150208}\n",
      "Losses {'ner': 5.0051109797695545}\n",
      "Losses {'ner': 12.04300357703137}\n",
      "Losses {'ner': 12.456989511468345}\n",
      "Losses {'ner': 16.04413301222518}\n",
      "Losses {'ner': 20.692603466445046}\n",
      "Losses {'ner': 1.0353312260049279}\n",
      "Losses {'ner': 1.2951031028372881}\n",
      "Losses {'ner': 6.556529195322923}\n",
      "Losses {'ner': 6.829594408200478}\n",
      "Losses {'ner': 16.210645580737378}\n",
      "Losses {'ner': 17.836333693135582}\n",
      "Losses {'ner': 1.9918716013198718}\n",
      "Losses {'ner': 6.930101677573475}\n",
      "Losses {'ner': 8.919141365136056}\n",
      "Losses {'ner': 9.115268172237151}\n",
      "Losses {'ner': 10.165925254089762}\n",
      "Losses {'ner': 15.893973150033508}\n",
      "Losses {'ner': 5.075964469608152}\n",
      "Losses {'ner': 7.212779473929004}\n",
      "Losses {'ner': 11.69300774572298}\n",
      "Losses {'ner': 12.462681615749943}\n",
      "Losses {'ner': 12.48741898865704}\n",
      "Losses {'ner': 13.994201607506042}\n",
      "Losses {'ner': 1.4673822964628331}\n",
      "Losses {'ner': 5.354888417032608}\n",
      "Losses {'ner': 6.631718670270285}\n",
      "Losses {'ner': 9.322197272713197}\n",
      "Losses {'ner': 12.655921938704369}\n",
      "Losses {'ner': 16.198029774717426}\n",
      "Losses {'ner': 3.9204421160432785}\n",
      "Losses {'ner': 5.802159743749775}\n",
      "Losses {'ner': 7.754498384694558}\n",
      "Losses {'ner': 9.542957256284865}\n",
      "Losses {'ner': 10.024830310102843}\n",
      "Losses {'ner': 13.774651448443144}\n",
      "Losses {'ner': 0.10113534708635186}\n",
      "Losses {'ner': 4.299474100545178}\n",
      "Losses {'ner': 4.390901370660456}\n",
      "Losses {'ner': 7.180457349876403}\n",
      "Losses {'ner': 9.21301369735988}\n",
      "Losses {'ner': 15.544312844230031}\n",
      "Losses {'ner': 1.3301455553942105}\n",
      "Losses {'ner': 1.615030082971948}\n",
      "Losses {'ner': 3.696595527387849}\n",
      "Losses {'ner': 3.743761493790814}\n",
      "Losses {'ner': 3.826526984741673}\n",
      "Losses {'ner': 4.564417028465755}\n",
      "Losses {'ner': 4.515594736521555}\n",
      "Losses {'ner': 6.831102217917012}\n",
      "Losses {'ner': 6.861871783305944}\n",
      "Losses {'ner': 9.898261651179311}\n",
      "Losses {'ner': 11.478909171831205}\n",
      "Losses {'ner': 12.04731685980706}\n",
      "Losses {'ner': 1.494106423710491}\n",
      "Losses {'ner': 4.8317990487147044}\n",
      "Losses {'ner': 4.911815351177122}\n",
      "Losses {'ner': 4.915790516223051}\n",
      "Losses {'ner': 5.204532293622935}\n",
      "Losses {'ner': 5.266165528605245}\n",
      "Losses {'ner': 3.8533765304650816}\n",
      "Losses {'ner': 4.074097828306546}\n",
      "Losses {'ner': 4.11251984193859}\n",
      "Losses {'ner': 5.819628372916353}\n",
      "Losses {'ner': 6.890028119734578}\n",
      "Losses {'ner': 9.0456846277324}\n",
      "Losses {'ner': 0.06716994580413455}\n",
      "Losses {'ner': 0.11058864702573123}\n",
      "Losses {'ner': 2.2768059275353445}\n",
      "Losses {'ner': 2.711802980227723}\n",
      "Losses {'ner': 8.439802506263561}\n",
      "Losses {'ner': 14.269821983907567}\n",
      "Losses {'ner': 0.44177038927930995}\n",
      "Losses {'ner': 0.661564643069801}\n",
      "Losses {'ner': 2.953891764163262}\n",
      "Losses {'ner': 5.656516565735439}\n",
      "Losses {'ner': 6.940014636585209}\n",
      "Losses {'ner': 7.683961450650404}\n"
     ]
    }
   ],
   "source": [
    "# TRAINING THE MODEL\n",
    "with nlp.disable_pipes(*unaffected_pipes):\n",
    "\n",
    "  # Training for 30 iterations\n",
    "  for iteration in range(30):\n",
    "\n",
    "    # shuufling examples  before every iteration\n",
    "    random.shuffle(TRAIN_DATA)\n",
    "    losses = {}\n",
    "    # batch up the examples using spaCy's minibatch\n",
    "    batches = minibatch(TRAIN_DATA, size=compounding(4.0, 32.0, 1.001))\n",
    "    for batch in batches:\n",
    "        texts, annotations = zip(*batch)\n",
    "        nlp.update(\n",
    "                    texts,  # batch of texts\n",
    "                    annotations,  # batch of annotations\n",
    "                    drop=0.5,  # dropout - make it harder to memorise data\n",
    "                    losses=losses,\n",
    "                )\n",
    "        print(\"Losses\", losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 713,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entities [('Wall Street', 'ORG')]\n"
     ]
    }
   ],
   "source": [
    "# Testing the model\n",
    "doc = nlp(\"Wall Street rises after Brexit.\")\n",
    "print(\"Entities\", [(ent.text, ent.label_) for ent in doc.ents])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 732,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model to \\model\n"
     ]
    }
   ],
   "source": [
    "# Save the  model to directory\n",
    "output_dir = Path('/model/')\n",
    "nlp.to_disk(output_dir)\n",
    "print(\"Saved model to\", output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 734,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading from \\model\n",
      "Entities [('Fridge', 'PRODUCT')]\n"
     ]
    }
   ],
   "source": [
    "# Load the saved model and predict\n",
    "print(\"Loading from\", output_dir)\n",
    "nlp_updated = spacy.load(output_dir)\n",
    "doc = nlp_updated(\"Fridge can be ordered in FlipKart\" )\n",
    "print(\"Entities\", [(ent.text, ent.label_) for ent in doc.ents])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
